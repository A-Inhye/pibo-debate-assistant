/**
 * live_transcription.js - ì‹¤ì‹œê°„ ìŒì„± ì „ì‚¬ ì›¹ UI
 *
 * WhisperLiveKitì˜ í”„ë¡ íŠ¸ì—”ë“œ JavaScript ì½”ë“œì…ë‹ˆë‹¤.
 * WebSocketì„ í†µí•´ ì„œë²„ì™€ í†µì‹ í•˜ë©° ì‹¤ì‹œê°„ ìŒì„± ì „ì‚¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
 *
 * ì£¼ìš” ê¸°ëŠ¥:
 *   1. ì˜¤ë””ì˜¤ ìº¡ì²˜: MediaRecorder ë˜ëŠ” AudioWorklet
 *   2. WebSocket í†µì‹ : ì˜¤ë””ì˜¤ ì „ì†¡ ë° ì „ì‚¬ ê²°ê³¼ ìˆ˜ì‹ 
 *   3. UI ì—…ë°ì´íŠ¸: ì „ì‚¬ ê²°ê³¼ í‘œì‹œ, íƒ€ì´ë¨¸, íŒŒí˜• ì‹œê°í™”
 *   4. í…Œë§ˆ ê´€ë¦¬: ë¼ì´íŠ¸/ë‹¤í¬/ì‹œìŠ¤í…œ ëª¨ë“œ
 *   5. ë§ˆì´í¬ ì„ íƒ: ì‚¬ìš© ê°€ëŠ¥í•œ ì˜¤ë””ì˜¤ ì…ë ¥ ì¥ì¹˜ ëª©ë¡
 *   6. í…ìŠ¤íŠ¸ ì½ê¸°: Web Speech APIë¥¼ ì‚¬ìš©í•œ TTS
 *
 * ì•„í‚¤í…ì²˜:
 *   - MediaRecorder ëª¨ë“œ (ê¸°ë³¸):
 *     ë§ˆì´í¬ â†’ MediaRecorder â†’ WebM/Opus â†’ WebSocket â†’ ì„œë²„
 *   - AudioWorklet ëª¨ë“œ (--pcm-input):
 *     ë§ˆì´í¬ â†’ AudioWorklet â†’ PCM Float32 â†’ Worker â†’ PCM Int16 â†’ WebSocket â†’ ì„œë²„
 *
 * ì „ì—­ ìƒíƒœ:
 *   - isRecording: ë…¹ìŒ ì¤‘ ì—¬ë¶€
 *   - websocket: WebSocket ì—°ê²° ê°ì²´
 *   - recorder: MediaRecorder ë˜ëŠ” null
 *   - audioContext: Web Audio API ì»¨í…ìŠ¤íŠ¸
 *   - workletNode: AudioWorkletNode (PCM ëª¨ë“œ)
 *   - recorderWorker: Web Worker (PCM ëª¨ë“œ)
 *
 * ì´ë²¤íŠ¸ íë¦„:
 *   1. ë…¹ìŒ ì‹œì‘ ë²„íŠ¼ í´ë¦­ â†’ toggleRecording()
 *   2. startRecording() â†’ WebSocket ì—°ê²° + ì˜¤ë””ì˜¤ ìº¡ì²˜ ì‹œì‘
 *   3. ì˜¤ë””ì˜¤ ë°ì´í„° â†’ WebSocket ì „ì†¡ (sendAudioData)
 *   4. WebSocket ë©”ì‹œì§€ ìˆ˜ì‹  â†’ updateTranscription()
 *   5. ë…¹ìŒ ì¤‘ì§€ â†’ stopRecording() â†’ ë¦¬ì†ŒìŠ¤ ì •ë¦¬
 */

// ============================================================================
// í™˜ê²½ ê°ì§€ ë° ì „ì—­ ë³€ìˆ˜
// ============================================================================

// Chrome í™•ì¥ í”„ë¡œê·¸ë¨ ê°ì§€
const isExtension = typeof chrome !== 'undefined' && chrome.runtime && chrome.runtime.getURL;
if (isExtension) {
  document.documentElement.classList.add('is-extension');
}
const isWebContext = !isExtension;

// ë…¹ìŒ ìƒíƒœ
let isRecording = false;           // ë…¹ìŒ ì¤‘ ì—¬ë¶€
let websocket = null;              // WebSocket ì—°ê²° ê°ì²´
let recorder = null;               // MediaRecorder ì¸ìŠ¤í„´ìŠ¤
let chunkDuration = 100;           // ì˜¤ë””ì˜¤ ì²­í¬ ì§€ì†ì‹œê°„ (ms)
let websocketUrl = "ws://localhost:8000/asr";  // WebSocket URL
let userClosing = false;           // ì‚¬ìš©ìê°€ ì˜ë„ì ìœ¼ë¡œ ì—°ê²° ì¢…ë£Œí–ˆëŠ”ì§€
let wakeLock = null;               // Screen Wake Lock (í™”ë©´ êº¼ì§ ë°©ì§€)
let startTime = null;              // ë…¹ìŒ ì‹œì‘ ì‹œê°„
let timerInterval = null;          // íƒ€ì´ë¨¸ ì¸í„°ë²Œ ID
let audioContext = null;           // Web Audio API ì»¨í…ìŠ¤íŠ¸
let analyser = null;               // ì˜¤ë””ì˜¤ ë¶„ì„ê¸° (íŒŒí˜• ì‹œê°í™”)
let microphone = null;             // ë§ˆì´í¬ ì…ë ¥ ìŠ¤íŠ¸ë¦¼
let workletNode = null;            // AudioWorkletNode (PCM ëª¨ë“œ)
let recorderWorker = null;         // Web Worker (PCM ë¦¬ìƒ˜í”Œë§)
let waveCanvas = document.getElementById("waveCanvas");  // íŒŒí˜• ìº”ë²„ìŠ¤
let waveCtx = waveCanvas.getContext("2d");              // ìº”ë²„ìŠ¤ ì»¨í…ìŠ¤íŠ¸
let animationFrame = null;         // ì• ë‹ˆë©”ì´ì…˜ í”„ë ˆì„ ID
let waitingForStop = false;        // ì„œë²„ì˜ ready_to_stop ëŒ€ê¸° ì¤‘
let lastReceivedData = null;       // ë§ˆì§€ë§‰ ìˆ˜ì‹  ë°ì´í„°
let lastSignature = null;          // ë§ˆì§€ë§‰ ë°ì´í„° ì‹œê·¸ë‹ˆì²˜ (ì¤‘ë³µ ë°©ì§€)
let availableMicrophones = [];     // ì‚¬ìš© ê°€ëŠ¥í•œ ë§ˆì´í¬ ëª©ë¡
let selectedMicrophoneId = null;   // ì„ íƒëœ ë§ˆì´í¬ ID
let serverUseAudioWorklet = null;  // ì„œë²„ê°€ AudioWorklet ì‚¬ìš© ì—¬ë¶€
let configReadyResolve;            // ì„œë²„ ì„¤ì • ì™„ë£Œ Promise ë¦¬ì¡¸ë²„
const configReady = new Promise((r) => (configReadyResolve = r));  // ì„¤ì • ì™„ë£Œ Promise
let outputAudioContext = null;     // TTS ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸
let audioSource = null;            // TTS ì˜¤ë””ì˜¤ ì†ŒìŠ¤

// ìº”ë²„ìŠ¤ í•´ìƒë„ ì„¤ì • (ê³ í•´ìƒë„ ë””ìŠ¤í”Œë ˆì´ ì§€ì›)
waveCanvas.width = 60 * (window.devicePixelRatio || 1);
waveCanvas.height = 30 * (window.devicePixelRatio || 1);
waveCtx.scale(window.devicePixelRatio || 1, window.devicePixelRatio || 1);

// DOM ìš”ì†Œ ì°¸ì¡°
const statusText = document.getElementById("status");
const recordButton = document.getElementById("recordButton");
const chunkSelector = document.getElementById("chunkSelector");
const websocketInput = document.getElementById("websocketInput");
const websocketDefaultSpan = document.getElementById("wsDefaultUrl");
const linesTranscriptDiv = document.getElementById("linesTranscript");
const timerElement = document.querySelector(".timer");
const themeRadios = document.querySelectorAll('input[name="theme"]');
const microphoneSelect = document.getElementById("microphoneSelect");

const settingsToggle = document.getElementById("settingsToggle");
const settingsDiv = document.querySelector(".settings");

// ============================================================================
// SVG ì•„ì´ì½˜ (ì¸ë¼ì¸)
// ============================================================================

// Chrome í™•ì¥ í”„ë¡œê·¸ë¨ìš© ì£¼ì„ ì²˜ë¦¬ëœ ì½”ë“œ
// if (isExtension) {
//   chrome.runtime.onInstalled.addListener((details) => {
//     if (details.reason.search(/install/g) === -1) {
//       return;
//     }
//     chrome.tabs.create({
//       url: chrome.runtime.getURL("welcome.html"),
//       active: true
//     });
//   });
// }

// UI ì•„ì´ì½˜ (SVG ì¸ë¼ì¸)
const translationIcon = `<svg xmlns="http://www.w3.org/2000/svg" height="12px" viewBox="0 -960 960 960" width="12px" fill="#5f6368"><path d="m603-202-34 97q-4 11-14 18t-22 7q-20 0-32.5-16.5T496-133l152-402q5-11 15-18t22-7h30q12 0 22 7t15 18l152 403q8 19-4 35.5T868-80q-13 0-22.5-7T831-106l-34-96H603ZM362-401 188-228q-11 11-27.5 11.5T132-228q-11-11-11-28t11-28l174-174q-35-35-63.5-80T190-640h84q20 39 40 68t48 58q33-33 68.5-92.5T484-720H80q-17 0-28.5-11.5T40-760q0-17 11.5-28.5T80-800h240v-40q0-17 11.5-28.5T360-880q17 0 28.5 11.5T400-840v40h240q17 0 28.5 11.5T680-760q0 17-11.5 28.5T640-720h-76q-21 72-63 148t-83 116l96 98-30 82-122-125Zm266 129h144l-72-204-72 204Z"/></svg>`
const silenceIcon = `<svg xmlns="http://www.w3.org/2000/svg" style="vertical-align: text-bottom;" height="14px" viewBox="0 -960 960 960" width="14px" fill="#5f6368"><path d="M514-556 320-752q9-3 19-5.5t21-2.5q66 0 113 47t47 113q0 11-1.5 22t-4.5 22ZM40-200v-32q0-33 17-62t47-44q51-26 115-44t141-18q26 0 49.5 2.5T456-392l-56-54q-9 3-19 4.5t-21 1.5q-66 0-113-47t-47-113q0-11 1.5-21t4.5-19L84-764q-11-11-11-28t11-28q12-12 28.5-12t27.5 12l675 685q11 11 11.5 27.5T816-80q-11 13-28 12.5T759-80L641-200h39q0 33-23.5 56.5T600-120H120q-33 0-56.5-23.5T40-200Zm80 0h480v-32q0-14-4.5-19.5T580-266q-36-18-92.5-36T360-320q-71 0-127.5 18T140-266q-9 5-14.5 14t-5.5 20v32Zm240 0Zm560-400q0 69-24.5 131.5T829-355q-12 14-30 15t-32-13q-13-13-12-31t12-33q30-38 46.5-85t16.5-98q0-51-16.5-97T767-781q-12-15-12.5-33t12.5-32q13-14 31.5-13.5T829-845q42 51 66.5 113.5T920-600Zm-182 0q0 32-10 61.5T700-484q-11 15-29.5 15.5T638-482q-13-13-13.5-31.5T633-549q6-11 9.5-24t3.5-27q0-14-3.5-27t-9.5-25q-9-17-8.5-35t13.5-31q14-14 32.5-13.5T700-716q18 25 28 54.5t10 61.5Z"/></svg>`;
const languageIcon = `<svg xmlns="http://www.w3.org/2000/svg" height="12" viewBox="0 -960 960 960" width="12" fill="#5f6368"><path d="M480-80q-82 0-155-31.5t-127.5-86Q143-252 111.5-325T80-480q0-83 31.5-155.5t86-127Q252-817 325-848.5T480-880q83 0 155.5 31.5t127 86q54.5 54.5 86 127T880-480q0 82-31.5 155t-86 127.5q-54.5 54.5-127 86T480-80Zm0-82q26-36 45-75t31-83H404q12 44 31 83t45 75Zm-104-16q-18-33-31.5-68.5T322-320H204q29 50 72.5 87t99.5 55Zm208 0q56-18 99.5-55t72.5-87H638q-9 38-22.5 73.5T584-178ZM170-400h136q-3-20-4.5-39.5T300-480q0-21 1.5-40.5T306-560H170q-5 20-7.5 39.5T160-480q0 21 2.5 40.5T170-400Zm216 0h188q3-20 4.5-39.5T580-480q0-21-1.5-40.5T574-560H386q-3 20-4.5 39.5T380-480q0 21 1.5 40.5T386-400Zm268 0h136q5-20 7.5-39.5T800-480q0-21-2.5-40.5T790-560H654q3 20 4.5 39.5T660-480q0 21-1.5 40.5T654-400Zm-16-240h118q-29-50-72.5-87T584-782q18 33 31.5 68.5T638-640Zm-234 0h152q-12-44-31-83t-45-75q-26 36-45 75t-31 83Zm-200 0h118q9-38 22.5-73.5T376-782q-56 18-99.5 55T204-640Z"/></svg>`
const speakerIcon = `<svg xmlns="http://www.w3.org/2000/svg" height="16px" style="vertical-align: text-bottom;" viewBox="0 -960 960 960" width="16px" fill="#5f6368"><path d="M480-480q-66 0-113-47t-47-113q0-66 47-113t113-47q66 0 113 47t47 113q0 66-47 113t-113 47ZM160-240v-32q0-34 17.5-62.5T224-378q62-31 126-46.5T480-440q66 0 130 15.5T736-378q29 15 46.5 43.5T800-272v32q0 33-23.5 56.5T720-160H240q-33 0-56.5-23.5T160-240Zm80 0h480v-32q0-11-5.5-20T700-306q-54-27-109-40.5T480-360q-56 0-111 13.5T260-306q-9 5-14.5 14t-5.5 20v32Zm240-320q33 0 56.5-23.5T560-640q0-33-23.5-56.5T480-720q-33 0-56.5 23.5T400-640q0 33 23.5 56.5T480-560Zm0-80Zm0 400Z"/></svg>`;

// ============================================================================
// í…Œë§ˆ ë° UI í—¬í¼ í•¨ìˆ˜
// ============================================================================

/**
 * íŒŒí˜• ìƒ‰ìƒ ê°€ì ¸ì˜¤ê¸° (CSS ë³€ìˆ˜)
 *
 * @returns {string} íŒŒí˜• ì„  ìƒ‰ìƒ
 */
function getWaveStroke() {
  const styles = getComputedStyle(document.documentElement);
  const v = styles.getPropertyValue("--wave-stroke").trim();
  return v || "#000";
}

let waveStroke = getWaveStroke();

/**
 * íŒŒí˜• ìƒ‰ìƒ ì—…ë°ì´íŠ¸ (í…Œë§ˆ ë³€ê²½ ì‹œ)
 */
function updateWaveStroke() {
  waveStroke = getWaveStroke();
}

/**
 * í…Œë§ˆ ì ìš©
 *
 * @param {string} pref - í…Œë§ˆ ì„¤ì • ("light" | "dark" | "system")
 */
function applyTheme(pref) {
  if (pref === "light") {
    document.documentElement.setAttribute("data-theme", "light");
  } else if (pref === "dark") {
    document.documentElement.setAttribute("data-theme", "dark");
  } else {
    document.documentElement.removeAttribute("data-theme");
  }
  updateWaveStroke();
}

// Persisted theme preference
const savedThemePref = localStorage.getItem("themePreference") || "system";
applyTheme(savedThemePref);
if (themeRadios.length) {
  themeRadios.forEach((r) => {
    r.checked = r.value === savedThemePref;
    r.addEventListener("change", () => {
      if (r.checked) {
        localStorage.setItem("themePreference", r.value);
        applyTheme(r.value);
      }
    });
  });
}

// React to OS theme changes when in "system" mode
const darkMq = window.matchMedia && window.matchMedia("(prefers-color-scheme: dark)");
const handleOsThemeChange = () => {
  const pref = localStorage.getItem("themePreference") || "system";
  if (pref === "system") updateWaveStroke();
};
if (darkMq && darkMq.addEventListener) {
  darkMq.addEventListener("change", handleOsThemeChange);
} else if (darkMq && darkMq.addListener) {
  // deprecated, but included for Safari compatibility
  darkMq.addListener(handleOsThemeChange);
}

/**
 * ë§ˆì´í¬ ëª©ë¡ ì—´ê±°
 *
 * navigator.mediaDevices.enumerateDevices()ë¥¼ ì‚¬ìš©í•˜ì—¬
 * ì‚¬ìš© ê°€ëŠ¥í•œ ì˜¤ë””ì˜¤ ì…ë ¥ ì¥ì¹˜ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
 *
 * ë™ì‘:
 *   1. ì„ì‹œë¡œ ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ (getUserMedia)
 *   2. ê¶Œí•œ íšë“ í›„ ì¦‰ì‹œ ìŠ¤íŠ¸ë¦¼ ì¤‘ì§€
 *   3. ì¥ì¹˜ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
 *   4. audioinput íƒ€ì…ë§Œ í•„í„°ë§
 *   5. ë“œë¡­ë‹¤ìš´ ë©”ë‰´ì— ì±„ìš°ê¸°
 *
 * Note:
 *   ë§ˆì´í¬ ë ˆì´ë¸”ì„ ê°€ì ¸ì˜¤ë ¤ë©´ ê¶Œí•œì´ í•„ìš”í•˜ë¯€ë¡œ
 *   ë¨¼ì € getUserMediaë¥¼ í˜¸ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.
 */
async function enumerateMicrophones() {
  try {
    // ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ (ë ˆì´ë¸” ê°€ì ¸ì˜¤ê¸° ìœ„í•´)
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    stream.getTracks().forEach(track => track.stop());

    // ì¥ì¹˜ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    const devices = await navigator.mediaDevices.enumerateDevices();
    availableMicrophones = devices.filter(device => device.kind === 'audioinput');

    populateMicrophoneSelect();
    console.log(`Found ${availableMicrophones.length} microphone(s)`);
  } catch (error) {
    console.error('Error enumerating microphones:', error);
    statusText.textContent = "Error accessing microphones. Please grant permission.";
  }
}

/**
 * ë§ˆì´í¬ ì„ íƒ ë“œë¡­ë‹¤ìš´ ì±„ìš°ê¸°
 *
 * availableMicrophones ëª©ë¡ì„ ì‚¬ìš©í•˜ì—¬
 * <select> ìš”ì†Œì— ì˜µì…˜ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
 * ì €ì¥ëœ ì„ íƒì„ ë³µì›í•©ë‹ˆë‹¤.
 */
function populateMicrophoneSelect() {
  if (!microphoneSelect) return;

  microphoneSelect.innerHTML = '<option value="">Default Microphone</option>';

  availableMicrophones.forEach((device, index) => {
    const option = document.createElement('option');
    option.value = device.deviceId;
    option.textContent = device.label || `Microphone ${index + 1}`;
    microphoneSelect.appendChild(option);
  });

  const savedMicId = localStorage.getItem('selectedMicrophone');
  if (savedMicId && availableMicrophones.some(mic => mic.deviceId === savedMicId)) {
    microphoneSelect.value = savedMicId;
    selectedMicrophoneId = savedMicId;
  }
}

function handleMicrophoneChange() {
  selectedMicrophoneId = microphoneSelect.value || null;
  localStorage.setItem('selectedMicrophone', selectedMicrophoneId || '');

  const selectedDevice = availableMicrophones.find(mic => mic.deviceId === selectedMicrophoneId);
  const deviceName = selectedDevice ? selectedDevice.label : 'Default Microphone';

  console.log(`Selected microphone: ${deviceName}`);
  statusText.textContent = `Microphone changed to: ${deviceName}`;

  if (isRecording) {
    statusText.textContent = "Switching microphone... Please wait.";
    stopRecording().then(() => {
      setTimeout(() => {
        toggleRecording();
      }, 1000);
    });
  }
}

// ============================================================================
// WebSocket ë° ì—°ê²° ì„¤ì •
// ============================================================================

/**
 * ìˆ«ì í¬ë§·íŒ… í—¬í¼ (ì†Œìˆ˜ì  1ìë¦¬)
 *
 * @param {any} x - í¬ë§·íŒ…í•  ê°’
 * @returns {string} í¬ë§·íŒ…ëœ ë¬¸ìì—´ ë˜ëŠ” ì›ë³¸ ê°’
 */
function fmt1(x) {
  const n = Number(x);
  return Number.isFinite(n) ? n.toFixed(1) : x;
}

// WebSocket URL ìë™ ê°ì§€
let host, port, protocol;
port = 8000;
if (isExtension) {
    host = "localhost";
    protocol = "ws";
} else {
    host = window.location.hostname || "localhost";
    port = window.location.port;
    protocol = window.location.protocol === "https:" ? "wss" : "ws";
}
const defaultWebSocketUrl = `${protocol}://${host}${port ? ":" + port : ""}/asr`;

// Populate default caption and input
if (websocketDefaultSpan) websocketDefaultSpan.textContent = defaultWebSocketUrl;
websocketInput.value = defaultWebSocketUrl;
websocketUrl = defaultWebSocketUrl;

// Optional chunk selector (guard for presence)
if (chunkSelector) {
  chunkSelector.addEventListener("change", () => {
    chunkDuration = parseInt(chunkSelector.value);
  });
}

// WebSocket input change handling
websocketInput.addEventListener("change", () => {
  const urlValue = websocketInput.value.trim();
  if (!urlValue.startsWith("ws://") && !urlValue.startsWith("wss://")) {
    statusText.textContent = "Invalid WebSocket URL (must start with ws:// or wss://)";
    return;
  }
  websocketUrl = urlValue;
  statusText.textContent = "WebSocket URL updated. Ready to connect.";
});

/**
 * WebSocket ì—°ê²° ì„¤ì •
 *
 * WebSocketì„ ìƒì„±í•˜ê³  ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ë¥¼ ë“±ë¡í•©ë‹ˆë‹¤.
 * Promiseë¥¼ ë°˜í™˜í•˜ì—¬ ì—°ê²° ì™„ë£Œë¥¼ ëŒ€ê¸°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
 *
 * ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬:
 *   - onopen: ì—°ê²° ì„±ê³µ ì‹œ resolve
 *   - onmessage: ì „ì‚¬ ê²°ê³¼ ìˆ˜ì‹  ì‹œ updateTranscription í˜¸ì¶œ
 *   - onerror: ì˜¤ë¥˜ ë°œìƒ ì‹œ reject
 *   - onclose: ì—°ê²° ì¢…ë£Œ ì‹œ ìƒíƒœ ì—…ë°ì´íŠ¸ ë° ì¬ì—°ê²°
 *
 * @returns {Promise<void>} ì—°ê²° ì„±ê³µ ì‹œ resolve
 */
function setupWebSocket() {
  return new Promise((resolve, reject) => {
    try {
      websocket = new WebSocket(websocketUrl);
    } catch (error) {
      statusText.textContent = "Invalid WebSocket URL. Please check and try again.";
      reject(error);
      return;
    }

    // ì—°ê²° ì„±ê³µ
    websocket.onopen = () => {
      statusText.textContent = "Connected to server.";
      resolve();
    };

    websocket.onclose = () => {
      if (userClosing) {
        if (waitingForStop) {
          statusText.textContent = "Processing finalized or connection closed.";
          if (lastReceivedData) {
          renderLinesWithBuffer(
              lastReceivedData.lines || [],
              lastReceivedData.buffer_diarization || "",
              lastReceivedData.buffer_transcription || "",
              lastReceivedData.buffer_translation || "",
              0,
              0,
              true
            );
          }
        }
      } else {
        statusText.textContent = "Disconnected from the WebSocket server. (Check logs if model is loading.)";
        if (isRecording) {
          stopRecording();
        }
      }
      isRecording = false;
      waitingForStop = false;
      userClosing = false;
      lastReceivedData = null;
      websocket = null;
      updateUI();
    };

    websocket.onerror = () => {
      statusText.textContent = "Error connecting to WebSocket.";
      reject(new Error("Error connecting to WebSocket"));
    };

    websocket.onmessage = (event) => {
      const data = JSON.parse(event.data);
      if (data.type === "config") {
        serverUseAudioWorklet = !!data.useAudioWorklet;
        statusText.textContent = serverUseAudioWorklet
          ? "Connected. Using AudioWorklet (PCM)."
          : "Connected. Using MediaRecorder (WebM).";
        if (configReadyResolve) configReadyResolve();
        return;
      }

      if (data.type === "ready_to_stop") {
        console.log("Ready to stop received, finalizing display and closing WebSocket.");
        waitingForStop = false;

        if (lastReceivedData) {
          renderLinesWithBuffer(
            lastReceivedData.lines || [],
            lastReceivedData.buffer_diarization || "",
            lastReceivedData.buffer_transcription || "",
            lastReceivedData.buffer_translation || "",
            0,
            0,
            true
          );
        }
        statusText.textContent = "Finished processing audio! Ready to record again.";
        recordButton.disabled = false;

        if (websocket) {
          websocket.close();
        }
        return;
      }

      lastReceivedData = data;

      const {
        lines = [],
        buffer_transcription = "",
        buffer_diarization = "",
        buffer_translation = "",
        remaining_time_transcription = 0,
        remaining_time_diarization = 0,
        status = "active_transcription",
        summary = null,
        timestamp_summaries = [],
        ai_response = null,
      } = data;

      // íƒ€ì„ìŠ¤íƒ¬í”„ ìš”ì•½ ì—…ë°ì´íŠ¸ (ì‹¤ì‹œê°„)
      if (timestamp_summaries && timestamp_summaries.length > 0) {
        updateTimestampSummaries(timestamp_summaries);
      }

      // AI ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ í‘œì‹œ
      if (ai_response) {
        console.log("ğŸ¤– AI ì‘ë‹µ:", ai_response.command, "â†’", ai_response.response);
        displayAIResponse(ai_response);
      }

      // ìš”ì•½ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ìš”ì•½ íŒ¨ë„ ì—…ë°ì´íŠ¸
      if (summary) {
        updateSummaryPanel(summary);
      }

      renderLinesWithBuffer(
        lines,
        buffer_diarization,
        buffer_transcription,
        buffer_translation,
        remaining_time_diarization,
        remaining_time_transcription,
        false,
        status
      );
    };
  });
}

/**
 * ìš”ì•½ íŒ¨ë„ ì—…ë°ì´íŠ¸
 *
 * ChatGPT APIì—ì„œ ë°›ì€ ìš”ì•½ ê²°ê³¼ë¥¼ Right Panelì— í‘œì‹œí•©ë‹ˆë‹¤.
 *
 * @param {Object} summaryData - ìš”ì•½ ê²°ê³¼ ê°ì²´
 *   ë°±ì—”ë“œ êµ¬ì¡°: { full: {...}, hierarchical: {...} }
 *   ë˜ëŠ” ì§ì ‘: { summary: "...", speaker_summaries: {...}, ... }
 */
function updateSummaryPanel(summaryData) {
  const container = document.getElementById('speakerSummary');
  if (!container || !summaryData) return;

  // ì¤‘ì²© êµ¬ì¡° ì²˜ë¦¬: summary.full ë˜ëŠ” summary.hierarchical ìš°ì„  ì‚¬ìš©
  let summary = summaryData;
  if (summaryData.hierarchical) {
    summary = summaryData.hierarchical;
  } else if (summaryData.full) {
    summary = summaryData.full;
  }

  let html = '';

  // ì—ëŸ¬ê°€ ìˆìœ¼ë©´ ì—ëŸ¬ í‘œì‹œ
  if (summary.error) {
    html = `
      <div class="summary-error">
        <p>Summary failed: ${escapeHtml(summary.error)}</p>
      </div>
    `;
    container.innerHTML = html;
    return;
  }

  // Summary
  if (summary.summary) {
    html += `
      <div class="summary-section">
        <h3 class="summary-title">Summary</h3>
        <p class="summary-text">${escapeHtml(summary.summary)}</p>
      </div>
    `;
  }

  // Speaker Arguments
  if (summary.speaker_summaries && Object.keys(summary.speaker_summaries).length > 0) {
    html += `<div class="summary-section"><h3 class="summary-title">Speaker Arguments</h3>`;
    for (const [speaker, argument] of Object.entries(summary.speaker_summaries)) {
      const speakerNum = parseInt(speaker) || speaker;
      html += `
        <div class="speaker-argument">
          <span class="speaker-badge speaker-${speakerNum}">Speaker ${speakerNum}</span>
          <p>${escapeHtml(argument)}</p>
        </div>
      `;
    }
    html += `</div>`;
  }

  // í† í° ì‚¬ìš©ëŸ‰ (ë””ë²„ê¹…ìš©)
  if (summary.token_usage) {
    html += `
      <div class="summary-meta">
        <small>Token usage: ${summary.token_usage}</small>
      </div>
    `;
  }

  container.innerHTML = html || '<div class="placeholder-message">No summary available.</div>';
}

/**
 * HTML ì´ìŠ¤ì¼€ì´í”„ ìœ í‹¸ë¦¬í‹°
 */
function escapeHtml(text) {
  if (!text) return '';
  const div = document.createElement('div');
  div.textContent = text;
  return div.innerHTML;
}

// íƒ€ì„ìŠ¤íƒ¬í”„ ìš”ì•½ ëˆ„ì  ì €ì¥
let accumulatedTimestampSummaries = [];

/**
 * íƒ€ì„ìŠ¤íƒ¬í”„ ìš”ì•½ ì—…ë°ì´íŠ¸ (ì‹¤ì‹œê°„)
 *
 * ì„œë²„ë¡œë¶€í„° ë°›ì€ íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜ ìš”ì•½ë“¤ì„ ì˜¤ë¥¸ìª½ íŒ¨ë„ì— í‘œì‹œí•©ë‹ˆë‹¤.
 * ìƒˆë¡œìš´ ìš”ì•½ì„ ê¸°ì¡´ ëª©ë¡ì— ì¶”ê°€í•˜ì—¬ ëˆ„ì  í‘œì‹œí•©ë‹ˆë‹¤.
 *
 * @param {Array} timestamp_summaries - ìƒˆë¡œ ë°›ì€ íƒ€ì„ìŠ¤íƒ¬í”„ ìš”ì•½ ë°°ì—´
 *   ì˜ˆ: [{ start: 0.0, end: 60.0, timestamp: "00:00 - 01:00", summary: "..." }, ...]
 */
function updateTimestampSummaries(timestamp_summaries) {
  const container = document.getElementById('timestampSummaries');
  const countElement = document.getElementById('timestampSummaryCount');

  if (!container) return;

  // ìƒˆë¡œìš´ ìš”ì•½ì„ ëˆ„ì  ëª©ë¡ì— ì¶”ê°€
  if (timestamp_summaries && timestamp_summaries.length > 0) {
    accumulatedTimestampSummaries.push(...timestamp_summaries);
  }

  // ìš”ì•½ ê°œìˆ˜ ì—…ë°ì´íŠ¸
  if (countElement) {
    countElement.textContent = `${accumulatedTimestampSummaries.length}ê°œ ìš”ì•½`;
  }

  // ìš”ì•½ì´ ì—†ìœ¼ë©´ í”Œë ˆì´ìŠ¤í™€ë” í‘œì‹œ
  if (accumulatedTimestampSummaries.length === 0) {
    container.innerHTML = `
      <div class="placeholder-message">
        <div class="placeholder-icon">â±ï¸</div>
        <p>ì‹¤ì‹œê°„ íƒ€ì„ìŠ¤íƒ¬í”„ ìš”ì•½ì´ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.</p>
      </div>
    `;
    return;
  }

  // íƒ€ì„ìŠ¤íƒ¬í”„ ìš”ì•½ HTML ìƒì„±
  let html = '';

  accumulatedTimestampSummaries.forEach((item, index) => {
    // ë°±ì—”ë“œì—ì„œ ì´ë¯¸ í¬ë§·íŒ…ëœ timestamp ì‚¬ìš©
    const timeRange = item.timestamp || `${Math.floor(item.start / 60)}:${Math.floor(item.start % 60).toString().padStart(2, '0')} - ${Math.floor(item.end / 60)}:${Math.floor(item.end % 60).toString().padStart(2, '0')}`;

    html += `
      <div class="timestamp-summary-item">
        <div class="timestamp-summary-header">
          <span class="timestamp-badge">${timeRange}</span>
        </div>
        <p class="timestamp-summary-text">${escapeHtml(item.summary)}</p>
      </div>
    `;
  });

  container.innerHTML = html;

  // ìŠ¤í¬ë¡¤ì„ ìµœì‹  ìš”ì•½ìœ¼ë¡œ ì´ë™
  const summaryContainer = document.getElementById('timestampSummaryContainer');
  if (summaryContainer) {
    summaryContainer.scrollTo({ top: summaryContainer.scrollHeight, behavior: 'smooth' });
  }
}

/**
 * AI ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ í‘œì‹œ
 *
 * íŒŒë™ì•„ ë“± ì›¨ì´í¬ì›Œë“œë¡œ í˜¸ì¶œëœ AI ì‘ë‹µì„ í™”ë©´ì— í‘œì‹œí•©ë‹ˆë‹¤.
 *
 * @param {Object} aiResponse - AI ì‘ë‹µ ê°ì²´
 *   ì˜ˆ: { command: "ìš”ì•½í•´ì¤˜", response: "í˜„ì¬ê¹Œì§€ì˜ í† ë¡ ì€...", timestamp: 1234567890 }
 */
function displayAIResponse(aiResponse) {
  if (!aiResponse || !aiResponse.response) return;

  console.log("AI ì‘ë‹µ ìˆ˜ì‹ :", aiResponse);

  // AI ì‘ë‹µ í‘œì‹œí•  ì»¨í…Œì´ë„ˆ (íƒ€ì„ìŠ¤íƒ¬í”„ ìš”ì•½ ìœ„ì— í‘œì‹œ)
  let aiContainer = document.getElementById('aiResponseContainer');

  if (!aiContainer) {
    // ì»¨í…Œì´ë„ˆê°€ ì—†ìœ¼ë©´ ìƒì„±
    const timestampContainer = document.getElementById('timestampSummaryContainer');
    if (timestampContainer) {
      aiContainer = document.createElement('div');
      aiContainer.id = 'aiResponseContainer';
      aiContainer.className = 'ai-response-container';
      timestampContainer.parentNode.insertBefore(aiContainer, timestampContainer);
    } else {
      return;
    }
  }

  // AI ì‘ë‹µ HTML ìƒì„±
  const html = `
    <div class="ai-response-card">
      <div class="ai-response-header">
        <img src="/web/padong.png" alt="íŒŒë™ì´" class="ai-icon-img">
        <span class="ai-name">íŒŒë™ì´</span>
        <span class="ai-command">"${escapeHtml(aiResponse.command)}"</span>
      </div>
      <div class="ai-response-content">
        ${escapeHtml(aiResponse.response)}
      </div>
    </div>
  `;

  aiContainer.innerHTML = html;
  aiContainer.style.display = 'block';

  // 5ì´ˆ í›„ ìë™ ìˆ¨ê¹€ (ì„ íƒì‚¬í•­)
  // setTimeout(() => {
  //   aiContainer.style.display = 'none';
  // }, 10000);
}

function renderLinesWithBuffer(
  lines,
  buffer_diarization,
  buffer_transcription,
  buffer_translation,
  remaining_time_diarization,
  remaining_time_transcription,
  isFinalizing = false,
  current_status = "active_transcription"
) {
  if (current_status === "no_audio_detected") {
    linesTranscriptDiv.innerHTML =
      "<p style='text-align: center; color: var(--muted); margin-top: 20px;'><em>No audio detected...</em></p>";
    return;
  }

  const showLoading = !isFinalizing && (lines || []).some((it) => it.speaker == 0);
  const showTransLag = !isFinalizing && remaining_time_transcription > 0;
  const showDiaLag = !isFinalizing && !!buffer_diarization && remaining_time_diarization > 0;
  const signature = JSON.stringify({
    lines: (lines || []).map((it) => ({ speaker: it.speaker, text: it.text, start: it.start, end: it.end, detected_language: it.detected_language })),
    buffer_transcription: buffer_transcription || "",
    buffer_diarization: buffer_diarization || "",
    buffer_translation: buffer_translation,
    status: current_status,
    showLoading,
    showTransLag,
    showDiaLag,
    isFinalizing: !!isFinalizing,
  });
  if (lastSignature === signature) {
    const t = document.querySelector(".lag-transcription-value");
    if (t) t.textContent = fmt1(remaining_time_transcription);
    const d = document.querySelector(".lag-diarization-value");
    if (d) d.textContent = fmt1(remaining_time_diarization);
    const ld = document.querySelector(".loading-diarization-value");
    if (ld) ld.textContent = fmt1(remaining_time_diarization);
    return;
  }
  lastSignature = signature;

  const linesHtml = (lines || [])
    .map((item, idx) => {
      let timeInfo = "";
      if (item.start !== undefined && item.end !== undefined) {
        timeInfo = ` ${item.start} - ${item.end}`;
      }

      let speakerLabel = "";
      if (item.speaker === -2) {
        speakerLabel = `<span class="silence">${silenceIcon}<span id='timeInfo'>${timeInfo}</span></span>`;
      } else if (item.speaker == 0 && !isFinalizing) {
        speakerLabel = `<span class='loading'><span class="spinner"></span><span id='timeInfo'><span class="loading-diarization-value">${fmt1(
          remaining_time_diarization
        )}</span> second(s) of audio are undergoing diarization</span></span>`;
      } else if (item.speaker !== 0) {
        const speakerNum = `<span class="speaker-badge">${item.speaker}</span>`;
        speakerLabel = `<span id="speaker">${speakerIcon}${speakerNum}<span id='timeInfo'>${timeInfo}</span></span>`;

        if (item.detected_language) {
          speakerLabel += `<span class="label_language">${languageIcon}<span>${item.detected_language}</span></span>`;
        }
      }

      let currentLineText = item.text || "";

      if (idx === lines.length - 1) {
        if (!isFinalizing && item.speaker !== -2) {
            speakerLabel += `<span class="label_transcription"><span class="spinner"></span>Transcription lag <span id='timeInfo'><span class="lag-transcription-value">${fmt1(
              remaining_time_transcription
            )}</span>s</span></span>`;

          if (buffer_diarization && remaining_time_diarization) {
            speakerLabel += `<span class="label_diarization"><span class="spinner"></span>Diarization lag<span id='timeInfo'><span class="lag-diarization-value">${fmt1(
              remaining_time_diarization
            )}</span>s</span></span>`;
          }
        }

        if (buffer_diarization) {
          if (isFinalizing) {
            currentLineText +=
              (currentLineText.length > 0 && buffer_diarization.trim().length > 0 ? " " : "") + buffer_diarization.trim();
          } else {
            currentLineText += `<span class="buffer_diarization">${buffer_diarization}</span>`;
          }
        }
        if (buffer_transcription) {
          if (isFinalizing) {
            currentLineText +=
              (currentLineText.length > 0 && buffer_transcription.trim().length > 0 ? " " : "") +
              buffer_transcription.trim();
          } else {
            currentLineText += `<span class="buffer_transcription">${buffer_transcription}</span>`;
          }
        }
      }
      let translationContent = "";
      if (item.translation) {
        translationContent += item.translation.trim();
      }
      if (idx === lines.length - 1 && buffer_translation) {
        const bufferPiece = isFinalizing
          ? buffer_translation
          : `<span class="buffer_translation">${buffer_translation}</span>`;
        translationContent += translationContent ? `${bufferPiece}` : bufferPiece;
      }
      if (translationContent.trim().length > 0) {
        currentLineText += `
            <div>
                <div class="label_translation">
                    ${translationIcon}
                    <span class="translation_text">${translationContent}</span>
                </div>
            </div>`;
      }

      return currentLineText.trim().length > 0 || speakerLabel.length > 0
        ? `<p>${speakerLabel}<br/><div class='textcontent'>${currentLineText}</div></p>`
        : `<p>${speakerLabel}<br/></p>`;
    })
    .join("");

  linesTranscriptDiv.innerHTML = linesHtml;
  const transcriptContainer = document.querySelector('.transcript-container');
  if (transcriptContainer) {
    transcriptContainer.scrollTo({ top: transcriptContainer.scrollHeight, behavior: "smooth" });
  }
}

function updateTimer() {
  if (!startTime) return;

  const elapsed = Math.floor((Date.now() - startTime) / 1000);
  const minutes = Math.floor(elapsed / 60).toString().padStart(2, "0");
  const seconds = (elapsed % 60).toString().padStart(2, "0");
  timerElement.textContent = `${minutes}:${seconds}`;
}

function drawWaveform() {
  if (!analyser) return;

  const bufferLength = analyser.frequencyBinCount;
  const dataArray = new Uint8Array(bufferLength);
  analyser.getByteTimeDomainData(dataArray);

  waveCtx.clearRect(
    0,
    0,
    waveCanvas.width / (window.devicePixelRatio || 1),
    waveCanvas.height / (window.devicePixelRatio || 1)
  );
  waveCtx.lineWidth = 1;
  waveCtx.strokeStyle = waveStroke;
  waveCtx.beginPath();

  const sliceWidth = (waveCanvas.width / (window.devicePixelRatio || 1)) / bufferLength;
  let x = 0;

  for (let i = 0; i < bufferLength; i++) {
    const v = dataArray[i] / 128.0;
    const y = (v * (waveCanvas.height / (window.devicePixelRatio || 1))) / 2;

    if (i === 0) {
      waveCtx.moveTo(x, y);
    } else {
      waveCtx.lineTo(x, y);
    }

    x += sliceWidth;
  }

  waveCtx.lineTo(
    waveCanvas.width / (window.devicePixelRatio || 1),
    (waveCanvas.height / (window.devicePixelRatio || 1)) / 2
  );
  waveCtx.stroke();

  animationFrame = requestAnimationFrame(drawWaveform);
}

// ============================================================================
// ë…¹ìŒ ì‹œì‘/ì¤‘ì§€ í•¨ìˆ˜
// ============================================================================

/**
 * ë…¹ìŒ ì‹œì‘
 *
 * WebSocket ì—°ê²° í›„ ë§ˆì´í¬ ìº¡ì²˜ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.
 * ì„œë²„ ì„¤ì •(useAudioWorklet)ì— ë”°ë¼ MediaRecorder ë˜ëŠ” AudioWorklet ëª¨ë“œë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
 *
 * ë™ì‘ íë¦„:
 *   1. Screen Wake Lock íšë“ (í™”ë©´ êº¼ì§ ë°©ì§€)
 *   2. ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ íšë“ (getUserMedia ë˜ëŠ” tabCapture)
 *   3. WebSocket ì—°ê²°
 *   4. ì„œë²„ ì„¤ì • ëŒ€ê¸° (config ë©”ì‹œì§€)
 *   5. ì˜¤ë””ì˜¤ ìº¡ì²˜ ëª¨ë“œ ì„ íƒ:
 *      - AudioWorklet ëª¨ë“œ: PCM Float32 â†’ Worker â†’ PCM Int16
 *      - MediaRecorder ëª¨ë“œ: WebM/Opus ì••ì¶•
 *   6. íƒ€ì´ë¨¸ ë° íŒŒí˜• ì‹œê°í™” ì‹œì‘
 *
 * AudioWorklet ëª¨ë“œ:
 *   - ë‚®ì€ ì§€ì—°ì‹œê°„, ë†’ì€ ëŒ€ì—­í­
 *   - PCM ë°ì´í„°ë¥¼ ì§ì ‘ ì „ì†¡
 *   - Web Workerì—ì„œ ë¦¬ìƒ˜í”Œë§ (48kHz â†’ 16kHz)
 *
 * MediaRecorder ëª¨ë“œ:
 *   - ì••ì¶• ì „ì†¡, ë‚®ì€ ëŒ€ì—­í­
 *   - WebM/Opus ì»¨í…Œì´ë„ˆ
 *   - ì„œë²„ì—ì„œ FFmpegë¡œ ë””ì½”ë”©
 *
 * @throws {Error} ë§ˆì´í¬ ê¶Œí•œ ê±°ë¶€, WebSocket ì—°ê²° ì‹¤íŒ¨ ë“±
 */
async function startRecording() {
  try {
    // íƒ€ì„ìŠ¤íƒ¬í”„ ìš”ì•½ ì´ˆê¸°í™” (ìƒˆ ì„¸ì…˜ ì‹œì‘)
    accumulatedTimestampSummaries = [];
    const timestampContainer = document.getElementById('timestampSummaries');
    if (timestampContainer) {
      timestampContainer.innerHTML = `
        <div class="placeholder-message">
          <div class="placeholder-icon">â±ï¸</div>
          <p>ì‹¤ì‹œê°„ íƒ€ì„ìŠ¤íƒ¬í”„ ìš”ì•½ì´ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.</p>
        </div>
      `;
    }
    const timestampCount = document.getElementById('timestampSummaryCount');
    if (timestampCount) {
      timestampCount.textContent = 'ì‹¤ì‹œê°„ ìš”ì•½';
    }

    // 1. Screen Wake Lock íšë“ (í™”ë©´ êº¼ì§ ë°©ì§€)
    try {
      wakeLock = await navigator.wakeLock.request("screen");
    } catch (err) {
      console.log("Error acquiring wake lock.");
    }

    let stream;
    
    // chromium extension. in the future, both chrome page audio and mic will be used
    if (isExtension) {
      try {
        stream = await new Promise((resolve, reject) => {
          chrome.tabCapture.capture({audio: true}, (s) => {
            if (s) {
              resolve(s);
            } else {
              reject(new Error('Tab capture failed or not available'));
            }
          });
        });
        
        try {
          outputAudioContext = new (window.AudioContext || window.webkitAudioContext)();
          audioSource = outputAudioContext.createMediaStreamSource(stream);
          audioSource.connect(outputAudioContext.destination);
        } catch (audioError) {
          console.warn('could not preserve system audio:', audioError);
        }
        
        statusText.textContent = "Using tab audio capture.";
      } catch (tabError) {
        console.log('Tab capture not available, falling back to microphone', tabError);
        const audioConstraints = selectedMicrophoneId
          ? { audio: { deviceId: { exact: selectedMicrophoneId } } }
          : { audio: true };
        stream = await navigator.mediaDevices.getUserMedia(audioConstraints);
        statusText.textContent = "Using microphone audio.";
      }
    } else if (isWebContext) {
      const audioConstraints = selectedMicrophoneId 
        ? { audio: { deviceId: { exact: selectedMicrophoneId } } }
        : { audio: true };
      stream = await navigator.mediaDevices.getUserMedia(audioConstraints);
    }

    audioContext = new (window.AudioContext || window.webkitAudioContext)();
    analyser = audioContext.createAnalyser();
    analyser.fftSize = 256;
    microphone = audioContext.createMediaStreamSource(stream);
    microphone.connect(analyser);

    if (serverUseAudioWorklet) {
      if (!audioContext.audioWorklet) {
        throw new Error("AudioWorklet is not supported in this browser");
      }
      await audioContext.audioWorklet.addModule("/web/pcm_worklet.js");
      workletNode = new AudioWorkletNode(audioContext, "pcm-forwarder", { numberOfInputs: 1, numberOfOutputs: 0, channelCount: 1 });
      microphone.connect(workletNode);

      recorderWorker = new Worker("/web/recorder_worker.js");
      recorderWorker.postMessage({
        command: "init",
        config: {
          sampleRate: audioContext.sampleRate,
        },
      });

      recorderWorker.onmessage = (e) => {
        if (websocket && websocket.readyState === WebSocket.OPEN) {
          websocket.send(e.data.buffer);
        }
      };

      workletNode.port.onmessage = (e) => {
        const data = e.data;
        const ab = data instanceof ArrayBuffer ? data : data.buffer;
        recorderWorker.postMessage(
          {
            command: "record",
            buffer: ab,
          },
          [ab]
        );
      };
    } else {
      try {
        recorder = new MediaRecorder(stream, { mimeType: "audio/webm" });
      } catch (e) {
        recorder = new MediaRecorder(stream);
      }
      recorder.ondataavailable = (e) => {
        if (websocket && websocket.readyState === WebSocket.OPEN) {
          if (e.data && e.data.size > 0) {
            websocket.send(e.data);
          }
        }
      };
      recorder.start(chunkDuration);
    }

    startTime = Date.now();
    timerInterval = setInterval(updateTimer, 1000);
    drawWaveform();

    isRecording = true;
    updateUI();
  } catch (err) {
    if (window.location.hostname === "0.0.0.0") {
      statusText.textContent =
        "Error accessing microphone. Browsers may block microphone access on 0.0.0.0. Try using localhost:8000 instead.";
    } else {
      statusText.textContent = "Error accessing microphone. Please allow microphone access.";
    }
    console.error(err);
  }
}

/**
 * ë…¹ìŒ ì¤‘ì§€
 *
 * ëª¨ë“  ì˜¤ë””ì˜¤ ìº¡ì²˜ë¥¼ ì¤‘ì§€í•˜ê³  ë¦¬ì†ŒìŠ¤ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.
 * ì„œë²„ì— ë¹ˆ Blobì„ ì „ì†¡í•˜ì—¬ ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œë¥¼ ì•Œë¦½ë‹ˆë‹¤.
 *
 * ì •ë¦¬ í•­ëª©:
 *   1. Screen Wake Lock í•´ì œ
 *   2. ì„œë²„ì— ë¹ˆ Blob ì „ì†¡ (ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ ì‹ í˜¸)
 *   3. MediaRecorder ì¤‘ì§€
 *   4. Web Worker ì¢…ë£Œ
 *   5. AudioWorkletNode ì—°ê²° í•´ì œ
 *   6. ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ì¤‘ì§€
 *   7. AudioContext ì¤‘ì§€
 *   8. íƒ€ì´ë¨¸ ë° ì• ë‹ˆë©”ì´ì…˜ ì¤‘ì§€
 *   9. ì„œë²„ì˜ ready_to_stop ë©”ì‹œì§€ ëŒ€ê¸°
 *
 * Note:
 *   waitingForStop í”Œë˜ê·¸ë¥¼ ì„¤ì •í•˜ì—¬ ì„œë²„ê°€ ëª¨ë“  ì˜¤ë””ì˜¤ë¥¼
 *   ì²˜ë¦¬í•  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦½ë‹ˆë‹¤. ready_to_stop ë©”ì‹œì§€ë¥¼ ë°›ìœ¼ë©´
 *   WebSocketì„ ë‹«ìŠµë‹ˆë‹¤.
 */
async function stopRecording() {
  // 1. Screen Wake Lock í•´ì œ
  if (wakeLock) {
    try {
      await wakeLock.release();
    } catch (e) {
      // ignore
    }
    wakeLock = null;
  }

  userClosing = true;         // ì‚¬ìš©ìê°€ ì˜ë„ì ìœ¼ë¡œ ì¢…ë£Œ
  waitingForStop = true;      // ì„œë²„ì˜ ready_to_stop ëŒ€ê¸°

  // 2. ì„œë²„ì— ë¹ˆ Blob ì „ì†¡ (ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ ì‹ í˜¸)
  if (websocket && websocket.readyState === WebSocket.OPEN) {
    const emptyBlob = new Blob([], { type: "audio/webm" });
    websocket.send(emptyBlob);
    statusText.textContent = "Recording stopped. Processing final audio...";
  }

  // 3. MediaRecorder ì¤‘ì§€
  if (recorder) {
    try {
      recorder.stop();
    } catch (e) {
      // ì´ë¯¸ ì¤‘ì§€ë¨
    }
    recorder = null;
  }

  // 4. Web Worker ì¢…ë£Œ (PCM ë¦¬ìƒ˜í”Œë§)
  if (recorderWorker) {
    recorderWorker.terminate();
    recorderWorker = null;
  }

  // 5. AudioWorkletNode ì—°ê²° í•´ì œ
  if (workletNode) {
    try {
      workletNode.port.onmessage = null;
    } catch (e) {}
    try {
      workletNode.disconnect();
    } catch (e) {}
    workletNode = null;
  }

  // 6. ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ì¤‘ì§€
  if (microphone) {
    microphone.disconnect();
    microphone = null;
  }

  if (analyser) {
    analyser = null;
  }

  if (audioContext && audioContext.state !== "closed") {
    try {
      await audioContext.close();
    } catch (e) {
      console.warn("Could not close audio context:", e);
    }
    audioContext = null;
  }

  if (audioSource) {
    audioSource.disconnect();
    audioSource = null;
  }

  if (outputAudioContext && outputAudioContext.state !== "closed") {
    outputAudioContext.close()
    outputAudioContext = null;
  }

  if (animationFrame) {
    cancelAnimationFrame(animationFrame);
    animationFrame = null;
  }

  if (timerInterval) {
    clearInterval(timerInterval);
    timerInterval = null;
  }
  timerElement.textContent = "00:00";
  startTime = null;

  isRecording = false;
  updateUI();
}

async function toggleRecording() {
  if (!isRecording) {
    if (waitingForStop) {
      console.log("Waiting for stop, early return");
      return;
    }
    console.log("Connecting to WebSocket");
    try {
      if (websocket && websocket.readyState === WebSocket.OPEN) {
        await configReady;
        await startRecording();
      } else {
        await setupWebSocket();
        await configReady;
        await startRecording();
      }
    } catch (err) {
      statusText.textContent = "Could not connect to WebSocket or access mic. Aborted.";
      console.error(err);
    }
  } else {
    console.log("Stopping recording");
    stopRecording();
  }
}

function updateUI() {
  recordButton.classList.toggle("recording", isRecording);
  recordButton.disabled = waitingForStop;

  if (waitingForStop) {
    // ì²˜ë¦¬ ëŒ€ê¸° ì¤‘ ë©”ì‹œì§€ ìˆ¨ê¹€
    statusText.textContent = "";
  } else if (isRecording) {
    statusText.textContent = "";
  } else {
    if (
      statusText.textContent !== "Finished processing audio! Ready to record again." &&
      statusText.textContent !== "Processing finalized or connection closed."
    ) {
      statusText.textContent = "Click to start transcription";
    }
  }
  if (!waitingForStop) {
    recordButton.disabled = false;
  }
}

recordButton.addEventListener("click", toggleRecording);

if (microphoneSelect) {
  microphoneSelect.addEventListener("change", handleMicrophoneChange);
}
document.addEventListener('DOMContentLoaded', async () => {
  try {
    await enumerateMicrophones();
  } catch (error) {
    console.log("Could not enumerate microphones on load:", error);
  }
});
navigator.mediaDevices.addEventListener('devicechange', async () => {
  console.log('Device change detected, re-enumerating microphones');
  try {
    await enumerateMicrophones();
  } catch (error) {
    console.log("Error re-enumerating microphones:", error);
  }
});


settingsToggle.addEventListener("click", () => {
settingsDiv.classList.toggle("visible");
settingsToggle.classList.toggle("active");
});

if (isExtension) {
  async function checkAndRequestPermissions() {
    const micPermission = await navigator.permissions.query({
      name: "microphone",
    });

    const permissionDisplay = document.getElementById("audioPermission");
    if (permissionDisplay) {
      permissionDisplay.innerText = `MICROPHONE: ${micPermission.state}`;
    }

    // if (micPermission.state !== "granted") {
    //   chrome.tabs.create({ url: "welcome.html" });
    // }

    const intervalId = setInterval(async () => {
      const micPermission = await navigator.permissions.query({
        name: "microphone",
      });
      if (micPermission.state === "granted") {
        if (permissionDisplay) {
          permissionDisplay.innerText = `MICROPHONE: ${micPermission.state}`;
        }
        clearInterval(intervalId);
      }
    }, 100);
  }

  void checkAndRequestPermissions();
}

// ================================
// í™”ìë³„ ìš”ì•½ ê¸°ëŠ¥ (íŒŒì´ë³´ í”„ë¡œì íŠ¸)
// ================================

/**
 * í™”ìë³„ ë©”ì‹œì§€ ë°ì´í„° ì €ì¥
 * í˜•ì‹: { "SPEAKER_00": ["ë°œì–¸1", "ë°œì–¸2", ...], "SPEAKER_01": [...], ... }
 */
const speakerMessages = {};

/**
 * í™”ìë³„ ìš”ì•½ ì—…ë°ì´íŠ¸
 *
 * í˜„ì¬ëŠ” í™”ìë³„ ë°œì–¸ ìˆ˜ë¥¼ í‘œì‹œí•˜ëŠ” ê°„ë‹¨í•œ ë²„ì „ì…ë‹ˆë‹¤.
 * ë‚˜ì¤‘ì— LLM APIë¥¼ ì—°ë™í•˜ì—¬ ì‹¤ì œ ë…¼ì§€ ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
 */
function updateSpeakerSummary() {
  const summaryContainer = document.getElementById('speakerSummary');

  // Show placeholder if no speakers
  if (Object.keys(speakerMessages).length === 0) {
    summaryContainer.innerHTML = `
      <div class="summary-placeholder">
        Speaker arguments will appear here when conversation starts.
      </div>
    `;
    return;
  }

  // í™”ìë³„ ìš”ì•½ HTML ìƒì„±
  let summaryHTML = '';

  for (const [speaker, messages] of Object.entries(speakerMessages)) {
    // í™”ì ì´ë¦„ í•œê¸€í™”
    const speakerName = speaker.replace('SPEAKER_', 'í™”ì ');

    // ìµœê·¼ 3ê°œ ë°œì–¸ë§Œ í‘œì‹œ
    const recentMessages = messages.slice(-3);

    summaryHTML += `
      <div class="speaker-summary-item">
        <h3>
          <span class="label_diarization">${speakerName}</span>
          <span style="font-size: 14px; font-weight: normal; color: var(--muted);">
            (ì´ ${messages.length}ê°œ ë°œì–¸)
          </span>
        </h3>
        <ul>
          ${recentMessages.map(msg => `<li>${msg}</li>`).join('')}
        </ul>
      </div>
    `;
  }

  summaryContainer.innerHTML = summaryHTML;
}

/**
 * í™”ì ë©”ì‹œì§€ ì¶”ê°€
 *
 * @param {string} speaker - í™”ì ID (ì˜ˆ: "SPEAKER_00")
 * @param {string} message - ë©”ì‹œì§€ ë‚´ìš©
 */
function addSpeakerMessage(speaker, message) {
  // í™”ìê°€ ì—†ìœ¼ë©´ ë°°ì—´ ì´ˆê¸°í™”
  if (!speakerMessages[speaker]) {
    speakerMessages[speaker] = [];
  }

  // ë©”ì‹œì§€ ì¶”ê°€ (ì¤‘ë³µ ì²´í¬)
  const trimmedMessage = message.trim();
  if (trimmedMessage && !speakerMessages[speaker].includes(trimmedMessage)) {
    speakerMessages[speaker].push(trimmedMessage);

    // ìš”ì•½ ì—…ë°ì´íŠ¸
    updateSpeakerSummary();
  }
}

/**
 * ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
 */
document.getElementById('refreshSummary')?.addEventListener('click', () => {
  updateSpeakerSummary();

  // ë²„íŠ¼ ì• ë‹ˆë©”ì´ì…˜
  const button = document.getElementById('refreshSummary');
  button.style.transform = 'rotate(360deg)';
  setTimeout(() => {
    button.style.transform = 'rotate(0deg)';
  }, 300);
});

/**
 * WebSocket ë©”ì‹œì§€ ì²˜ë¦¬ ìˆ˜ì •
 *
 * ê¸°ì¡´ displayTranscript í•¨ìˆ˜ë¥¼ í™•ì¥í•˜ì—¬ í™”ìë³„ ë©”ì‹œì§€ë¥¼ ì¶”ì í•©ë‹ˆë‹¤.
 * ì´ í•¨ìˆ˜ëŠ” ê¸°ì¡´ ì½”ë“œì˜ displayTranscriptë¥¼ ë˜í•‘í•©ë‹ˆë‹¤.
 */
const originalDisplayTranscript = window.displayTranscript;
if (originalDisplayTranscript) {
  window.displayTranscript = function(data) {
    // ê¸°ì¡´ í•¨ìˆ˜ ì‹¤í–‰
    originalDisplayTranscript(data);

    // í™”ì ì •ë³´ ì¶”ì¶œ ë° ì €ì¥
    if (data.speaker && data.text) {
      addSpeakerMessage(data.speaker, data.text);
    }
  };
}

// ì´ˆê¸° í”Œë ˆì´ìŠ¤í™€ë” í‘œì‹œ
updateSpeakerSummary();
